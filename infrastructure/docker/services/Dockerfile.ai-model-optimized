# Оптимизированный Dockerfile для AI Model Service
FROM python:3.11-slim

# Устанавливаем системные зависимости
RUN apt-get update && apt-get install -y \
    git \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Устанавливаем переменные окружения для оптимизации
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV TORCH_CUDA_ARCH_LIST="6.0;6.1;7.0;7.5;8.0;8.6"
ENV CUDA_HOME=/usr/local/cuda

# Создаем рабочую директорию
WORKDIR /app

# Устанавливаем Python зависимости с оптимизациями
RUN pip install --no-cache-dir --upgrade pip

# Устанавливаем основные зависимости
RUN pip install --no-cache-dir \
    fastapi==0.104.1 \
    uvicorn[standard]==0.24.0 \
    uvloop==0.19.0 \
    httptools==0.6.1 \
    redis==5.0.1 \
    pydantic==2.5.0 \
    psutil \
    torch>=2.6.0 \
    torchvision>=0.17.0 \
    torchaudio>=2.6.0 \
    transformers==4.54.1 \
    accelerate>=0.25.0 \
    sentence-transformers==2.2.2 \
    faiss-cpu==1.7.4 \
    numpy==1.24.3 \
    scikit-learn==1.3.2

# Копируем исходный код
COPY src/ /app/src/

# Создаем необходимые директории
RUN mkdir -p /app/models /app/logs /app/data

# Порт для сервиса
EXPOSE 8003

# Запускаем оптимизированный сервис
CMD ["python3", "/app/src/infrastructure/api/__main__.py"] 