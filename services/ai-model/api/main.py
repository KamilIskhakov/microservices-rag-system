"""
AI Model Service API - –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–π –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å
"""
import asyncio
import logging
import time
import multiprocessing
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from datetime import datetime
from typing import Dict, Any, List, Optional
import os
import sys

import torch
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import psutil

sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from domain.services.model_service import ModelService
from infrastructure.persistence.optimized_model_repository import OptimizedModelRepository
from application.use_cases.generate_text import GenerateTextUseCase, GenerateTextRequest

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = FastAPI(title="AI Model Service", version="2.0.0")

model_service: Optional[ModelService] = None
generate_text_use_case: Optional[GenerateTextUseCase] = None

thread_pool: Optional[ThreadPoolExecutor] = None
process_pool: Optional[ProcessPoolExecutor] = None

MAX_WORKERS = int(os.getenv("MAX_WORKERS", "8"))
MAX_PROCESSES = int(os.getenv("MAX_PROCESSES", "2"))


class ModelRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞"""
    query: str
    context: List[str] = []
    max_length: int = 512
    temperature: float = 0.7
    model_id: str = "qwen-model_full"
    use_async: bool = True


class ModelResponse(BaseModel):
    """–û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏"""
    success: bool
    result: str
    processing_time: float
    timestamp: str
    model_id: Optional[str] = None
    error: Optional[str] = None
    memory_usage: Optional[Dict[str, Any]] = None


class ModelInfo(BaseModel):
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
    model_id: str
    name: str
    type: str
    device: str
    is_loaded: bool
    memory_usage: Optional[Dict[str, Any]] = None


class SystemInfo(BaseModel):
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ"""
    cpu_count: int
    memory_total: float
    memory_available: float
    memory_percent: float
    thread_pool_workers: int
    process_pool_workers: int
    loaded_models_count: int


@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ"""
    global model_service, generate_text_use_case, thread_pool, process_pool
    
    try:
        logger.info("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI Model Service...")
        
        model_repository = OptimizedModelRepository()
        
        model_service = ModelService(model_repository)
        
        generate_text_use_case = GenerateTextUseCase(model_service)
        
        thread_pool = ThreadPoolExecutor(max_workers=MAX_WORKERS)
        process_pool = ProcessPoolExecutor(max_workers=MAX_PROCESSES)
        
        logger.info("‚úÖ AI Model Service –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ AI Model Service: {e}")
        raise


@app.on_event("shutdown")
async def shutdown_event():
    """–û—á–∏—Å—Ç–∫–∞ –ø—Ä–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–∏"""
    global thread_pool, process_pool
    
    try:
        logger.info("üõë –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã AI Model Service...")
        
        if thread_pool:
            thread_pool.shutdown(wait=True)
        
        if process_pool:
            process_pool.shutdown(wait=True)
        
        logger.info("‚úÖ AI Model Service –∑–∞–≤–µ—Ä—à–µ–Ω")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è AI Model Service: {e}")


@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    try:
        if model_service is None:
            return {"status": "unhealthy", "error": "Service not initialized"}
        
        loaded_models = model_service.get_loaded_models()
        
        return {
            "status": "healthy",
            "service": "ai-model",
            "timestamp": datetime.now().isoformat(),
            "loaded_models_count": len(loaded_models),
            "memory_usage": model_service.get_memory_usage()
        }
        
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        return {"status": "unhealthy", "error": str(e)}


@app.get("/system-info", response_model=SystemInfo)
async def get_system_info():
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∏—Å—Ç–µ–º–µ"""
    try:
        memory = psutil.virtual_memory()
        
        return SystemInfo(
            cpu_count=psutil.cpu_count(),
            memory_total=memory.total / 1024 / 1024 / 1024,  # GB
            memory_available=memory.available / 1024 / 1024 / 1024,  # GB
            memory_percent=memory.percent,
            thread_pool_workers=MAX_WORKERS,
            process_pool_workers=MAX_PROCESSES,
            loaded_models_count=len(model_service.get_loaded_models()) if model_service else 0
        )
        
    except Exception as e:
        logger.error(f"Error getting system info: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/load-model")
async def load_model(model_id: str = "qwen-model_full", device: str = "auto"):
    """–ó–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å"""
    try:
        if model_service is None:
            raise HTTPException(status_code=503, detail="Service not initialized")
        
        logger.info(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å: {model_id}")
        model = model_service.load_model(model_id, device)
        
        return {
            "success": True,
            "model_id": model.id,
            "name": model.name,
            "device": model.device,
            "is_loaded": model.is_loaded
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/unload-model")
async def unload_model(model_id: str):
    """–í—ã–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å"""
    try:
        if model_service is None:
            raise HTTPException(status_code=503, detail="Service not initialized")
        
        logger.info(f"–í—ã–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å: {model_id}")
        success = model_service.unload_model(model_id)
        
        return {
            "success": success,
            "model_id": model_id
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤—ã–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/generate", response_model=ModelResponse)
async def generate_response(request: ModelRequest):
    """–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏"""
    try:
        if generate_text_use_case is None:
            raise HTTPException(status_code=503, detail="Service not initialized")
        
        logger.info(f"–ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç –¥–ª—è –º–æ–¥–µ–ª–∏: {request.model_id}")
        
        use_case_request = GenerateTextRequest(
            query=request.query,
            context=request.context,
            max_length=request.max_length,
            temperature=request.temperature,
            model_id=request.model_id
        )
        
        response = generate_text_use_case.execute(use_case_request)
        
        memory_usage = model_service.get_memory_usage() if model_service else None
        
        return ModelResponse(
            success=response.success,
            result=response.result,
            processing_time=response.processing_time,
            timestamp=datetime.now().isoformat(),
            model_id=response.model_id,
            error=response.error,
            memory_usage=memory_usage
        )
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/models", response_model=List[ModelInfo])
async def get_models():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
    try:
        if model_service is None:
            raise HTTPException(status_code=503, detail="Service not initialized")
        
        models = model_service.get_loaded_models()
        
        result = []
        for model in models:
            model_info = model_service.get_model_info(model.id)
            if model_info:
                result.append(ModelInfo(**model_info))
        
        return result
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/model/{model_id}")
async def get_model_info(model_id: str):
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    try:
        if model_service is None:
            raise HTTPException(status_code=503, detail="Service not initialized")
        
        model_info = model_service.get_model_info(model_id)
        if not model_info:
            raise HTTPException(status_code=404, detail="Model not found")
        
        return model_info
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/optimize-memory")
async def optimize_memory():
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏"""
    try:
        if model_service is None:
            raise HTTPException(status_code=503, detail="Service not initialized")
        
        logger.info("–û–ø—Ç–∏–º–∏–∑–∏—Ä—É–µ–º –ø–∞–º—è—Ç—å...")
        model_service.optimize_memory()
        
        return {
            "success": True,
            "message": "Memory optimized successfully"
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–∞–º—è—Ç–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/memory-usage")
async def get_memory_usage():
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ –ø–∞–º—è—Ç–∏"""
    try:
        if model_service is None:
            raise HTTPException(status_code=503, detail="Service not initialized")
        
        return model_service.get_memory_usage()
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø–∞–º—è—Ç–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8003)
